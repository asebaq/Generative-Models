{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('test': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "colab": {
   "name": "Test_GAN_pytorch.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {}
  },
  "interpreter": {
   "hash": "613189b9447b40282886222006ee8b14fcbe993fdc86fe1dc10aaac86284b79c"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import libraries and load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.utils as vutils\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
    "data = datasets.MNIST(root='./data',download=True, transform=transform)\n",
    "img_shape = (data[1][0].size(0), data[1][0].size(1), data[1][0].size(2))\n",
    "print(f'Input size is {img_shape}')\n",
    "\n",
    "# Prepare dataloader for training\n",
    "batch_size = 256\n",
    "dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.axis('off')\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0][:16], padding=2, normalize=True).cpu(),(1,2,0)))"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 152
    },
    "id": "464a2095-c213-4fcf-9d7e-8983e00872be",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1631052327658,
     "user_tz": -540,
     "elapsed": 456,
     "user": {
      "displayName": "­송기웅 / 학생 / 수리과학부",
      "photoUrl": "",
      "userId": "01789665999382241061"
     }
    },
    "outputId": "84ead153-0c8b-4c68-bd69-d859f7080beb"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build Vanilla GAN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from GAN_pytorch import Generator, Discriminator, Train\n",
    "\n",
    "dim_latent = 100\n",
    "lr = 0.001\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if cuda else 'cpu')\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "G = Generator(img_shape=img_shape, dim_latent=dim_latent, g_dims=[128,256,512,1024]).to(device)\n",
    "D = Discriminator(img_shape=img_shape, d_dims=[512, 256]).to(device)\n",
    "\n",
    "optimizer_G = torch.optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "4ea5db7d-7205-464b-99ae-48d9513cd8a3",
    "executionInfo": {
     "status": "error",
     "timestamp": 1631052339708,
     "user_tz": -540,
     "elapsed": 380,
     "user": {
      "displayName": "­송기웅 / 학생 / 수리과학부",
      "photoUrl": "",
      "userId": "01789665999382241061"
     }
    },
    "outputId": "28cbe55e-beda-4d03-f6d6-820c1821941d"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Train(epoch=50, dataloader=dataloader, device=device, G=G, D=D,\n",
    "      optimizer_G=optimizer_G, optimizer_D=optimizer_D)\n",
    "\n",
    "# Save trained model if needed\n",
    "torch.save(G, './vanilla_G.pt')\n",
    "torch.save(D, './vanilla_D.pt')\n",
    "\n",
    "# Load trained model if needed\n",
    "G = torch.load('./vanilla_G.pt')\n",
    "D = torch.load('./vanilla_D.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Examples of Generated Images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "G.eval()\n",
    "z = torch.rand(16, dim_latent).to(device)\n",
    "fake = G(z).detach().cpu()\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.axis('off')\n",
    "plt.imshow(np.transpose(vutils.make_grid(fake, padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "id": "9ee0dd55-c8b7-47c0-9a4c-537918be3f96",
    "outputId": "e2718b5d-d3f2-435c-c753-8dd33e1b292e"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
